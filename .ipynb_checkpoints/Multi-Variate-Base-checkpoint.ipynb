{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "67j8odKJJQL_"
   },
   "source": [
    "## Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qd88JeQfrEzc"
   },
   "outputs": [],
   "source": [
    "from fbprophet import Prophet\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from utils import *\n",
    "import warnings\n",
    "\n",
    "# plt.style.use('dark_background')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def universe_select(path, commodity_name):\n",
    "    \"\"\"Selects the instruments believed to be of\n",
    "    interest for the commodity selected\n",
    "    Returns: A dictionary of dataframes which are\n",
    "    intruments of interest\"\"\"\n",
    "    universe_dict = {}\n",
    "    \n",
    "    if commodity_name == \"Al\": \n",
    "        aluminium_list = [\"al_shfe\", \"al_lme\", \"al_comex_p\", \"al_comex_s\", \"al_lme_s\", \"yuan\",\n",
    "                 \"bdi\", \"ted\", \"vix\", \"skew\", \"gsci\"]\n",
    "        \n",
    "        for instrument in aluminium_list:\n",
    "            df = pd.read_csv(path + instrument + \".csv\", index_col='date', parse_dates=['date'], dayfirst=True).sort_index(ascending=True)\n",
    "            universe_dict[instrument] = df\n",
    "            \n",
    "    elif commodity_name == \"Cu\":\n",
    "        copper_list = [\"cu_shfe\", \"cu_lme\", \"cu_comex_p\", \"cu_comex_s\", \"peso\", \"sol\",\n",
    "                 \"bdi\", \"ted\", \"vix\", \"skew\", \"gsci\"]\n",
    "        \n",
    "        for instrument in copper_list:\n",
    "            df = pd.read_csv(path + instrument + \".csv\", index_col='date', parse_dates=['date'], dayfirst=True).sort_index(ascending=True)\n",
    "            universe_dict[instrument] = df\n",
    "    \n",
    "    else: print(\"Select an appropriate commodity\")\n",
    "    return universe_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Data/\"\n",
    "universe_dict = universe_select(path, \"Cu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4k8FIHASpHfv"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ki2dJCGNkOVE",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Included Instrument:\n",
      "cu_shfe\n",
      "cu_lme\n",
      "cu_comex_p\n",
      "cu_comex_s\n",
      "peso\n",
      "sol\n",
      "bdi\n",
      "ted\n",
      "vix\n",
      "skew\n",
      "gsci\n"
     ]
    }
   ],
   "source": [
    "# Renaming the columns to price\n",
    "universe_dict = price_rename(universe_dict)\n",
    "# Cleaning the dataset of any erroneous datapoints\n",
    "universe_dict = clean_dict_gen(universe_dict)\n",
    "# Making sure that all the points in the window have consistent lenght\n",
    "universe_dict = truncate_window_length(universe_dict)\n",
    "# Generate the full training dataset\n",
    "df_full = generate_dataset(universe_dict, lg_returns_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualise the plots\n",
    "# visualise_universe(universe_dict)\n",
    "df = df_full[['lg_return_cu_lme']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lg_return_cu_lme</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-08-29</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-08-30</th>\n",
       "      <td>0.007395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-08-31</th>\n",
       "      <td>0.033459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-09-01</th>\n",
       "      <td>-0.014616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-09-04</th>\n",
       "      <td>0.008117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            lg_return_cu_lme\n",
       "date                        \n",
       "2006-08-29          0.000000\n",
       "2006-08-30          0.007395\n",
       "2006-08-31          0.033459\n",
       "2006-09-01         -0.014616\n",
       "2006-09-04          0.008117"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_spawn(df):\n",
    "  \"\"\"Spawns features for each instrument\n",
    "  Returns df with the following columns for each\n",
    "  instrument\n",
    "  Log Returns\n",
    "  EWMA 1 day\n",
    "  EWMA 1 week\n",
    "  EWMA 1 month\n",
    "  EWMA 1 quarter\n",
    "  EWMA 6 months\n",
    "  EWMA 1 year\n",
    "  Rolling vol 1 week\n",
    "  Rolling vol 1 month\n",
    "  Rolling vol 1 quarter\n",
    "  \"\"\"\n",
    "  hlf_dict = {\"week\":5, \"month\":22, \"quarter\":66, \"half_year\":130, \"year\":261}\n",
    "    \n",
    "  for col in df.columns:\n",
    "      for half_life in hlf_dict:\n",
    "        df[col + \"_ema_\" + half_life] = df[col].ewm(span=hlf_dict[half_life]).mean()\n",
    "\n",
    "      for i, half_life in enumerate(hlf_dict):\n",
    "        if i < 3:\n",
    "          df[col + \"_roll_vol_\" + half_life] = df[col].rolling(window=hlf_dict[half_life]).std(ddof=0)\n",
    "  \n",
    "  df.dropna(inplace=True)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = feature_spawn(df_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dimensions: 6\n",
      "Explained Variance: [0.88530351 0.0773672  0.00956477 0.00848314 0.00755128 0.00682361] \n",
      "Explained Variance Sum: 0.9950935118227293\n"
     ]
    }
   ],
   "source": [
    "def dimension_selector(df, thresh=0.99):\n",
    "  \"\"\"Returns the number of dimensions that reaches the \n",
    "  threshold level of desired variance\"\"\"\n",
    "  for n_dim in range(1, 11):\n",
    "    pca = PCA(n_components=n_dim)\n",
    "    pca.fit(df)\n",
    "    if sum(pca.explained_variance_ratio_) > thresh: \n",
    "      print(\"Number of dimensions:\", n_dim)\n",
    "      return n_dim\n",
    "  print(\"No level of dimensionality reaches threshold variance level\")\n",
    "  return None\n",
    "\n",
    "\n",
    "def dimension_reduce(df, n_dim):\n",
    "  \"\"\"\"\"\"\n",
    "  pca = PCA(n_components=n_dim)\n",
    "  pca.fit(df)\n",
    "  df_reduced = pca.transform(df) \n",
    "  print(\"Explained Variance:\", pca.explained_variance_ratio_, \n",
    "     \"\\nExplained Variance Sum:\", sum(pca.explained_variance_ratio_))\n",
    "  return pd.DataFrame(df_reduced, index=df.index)\n",
    "\n",
    "\n",
    "def inverse_pca(df_reduced, df, n_dim):\n",
    "  \"\"\"\"\"\"\n",
    "  pca = PCA(n_components=n_dim)\n",
    "  pca.fit(df)\n",
    "  df_inverse = pd.DataFrame(pca.inverse_transform(pca_reduced), index=df.index, columns=df.columns)\n",
    "  return \n",
    "\n",
    "n_dim = dimension_selector(df_full)\n",
    "df_reduced = dimension_reduce(df_full, n_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Chai_Base.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
