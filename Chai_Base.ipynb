{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chai_Base.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msc-acse/acse-9-independent-research-project-OliverJBoom/blob/master/Chai_Base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoQwCUvlJEV-",
        "colab_type": "text"
      },
      "source": [
        "## Linking to Github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTqLeUfqHP6b",
        "colab_type": "code",
        "outputId": "fea468e5-cdf1-4653-dcc3-773f79a4e45a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "user = \"OliverJBoom\"\n",
        "password = getpass('github password')\n",
        "os.environ['GITHUB_AUTH'] = user + ':' + password\n",
        "\n",
        "!rm -rf Chai_Base\n",
        "!git clone https://$GITHUB_AUTH@github.com/msc-acse/acse-9-independent-research-project-OliverJBoom.git Chai_Base"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "github password··········\n",
            "Cloning into 'Chai_Base'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 17 (delta 3), reused 12 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (17/17), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKJiIZXUJLqw",
        "colab_type": "text"
      },
      "source": [
        "## Linking to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAtL1eUQnKTM",
        "colab_type": "code",
        "outputId": "3c1a5ff1-9c39-49f8-cae7-0ee00c566cd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive/\")\n",
        "path = \"/content/gdrive/My Drive/Chai/Data\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67j8odKJJQL_",
        "colab_type": "text"
      },
      "source": [
        "## Loading Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qd88JeQfrEzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.tsa.stattools import adfuller"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmQo7bszJT7F",
        "colab_type": "text"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP_Lko5woTfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cu_lme =  pd.read_csv(\"/content/gdrive/My Drive/Chai/Data/CuLME.csv\", index_col='date', parse_dates=['date'], dayfirst=True).sort_index(ascending=True)\n",
        "cu_shfe =  pd.read_csv(\"/content/gdrive/My Drive/Chai/Data/CuSHFE.csv\", index_col='date', parse_dates=['date'], dayfirst=True).sort_index(ascending=True)\n",
        "cu_com_s =  pd.read_csv(\"/content/gdrive/My Drive/Chai/Data/CuCOMS.csv\", index_col='date', parse_dates=['date'], dayfirst=True).sort_index(ascending=True)\n",
        "cu_com_p =  pd.read_csv(\"/content/gdrive/My Drive/Chai/Data/CuCOMP.csv\", index_col='date', parse_dates=['date'], dayfirst=True).sort_index(ascending=True)\n",
        "\n",
        "universe_dict = {\"lme\":cu_lme, \"shfe\":cu_shfe, \"com s\":cu_com_s, \"com p\":cu_com_p}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIncbWl0rXUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualise_plots(universe_dict, frequency=\"MS\"):\n",
        "  \"\"\"Plotting the line graph for all of the \n",
        "  instruments being inspected\"\"\"\n",
        "  for df_name in universe_dict:\n",
        "    df = universe_dict[df_name]\n",
        "    plt.plot(df.index, df.price)\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"Price\")\n",
        "    plt.title(df_name)\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "    \n",
        "# visualise_plots(universe_dict)\n",
        "# df.info()\n",
        "# plt.hist((df.price), bins=20)\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k8FIHASpHfv",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYBhMxv-5nEV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9df29b88-646b-4f57-9c0d-8b460c9f7ce4"
      },
      "source": [
        "def price_rename(universe_dict):\n",
        "  \"\"\"Renaming the column of the dataframe values to price\"\"\"\n",
        "  for df_name in universe_dict:\n",
        "    df = universe_dict[df_name]\n",
        "    df = df.rename(columns={'value':\"price\"})\n",
        "    universe_dict[df_name] = df\n",
        "  return universe_dict\n",
        "\n",
        "\n",
        "def clean_data(df, n_std = 20):\n",
        "  \"\"\"Removes any outliers that are further than a chosen\n",
        "  number of standard deviations from the mean\"\"\"\n",
        "  upper = df.price.mean() + n_std * (df.price.std())\n",
        "  lower = df.price.mean() - n_std * (df.price.std())\n",
        "  df.loc[((df.price > upper) | (df.price < lower)), 'price'] = None\n",
        "  df.ffill(inplace=True)\n",
        "  if df.price.isnull().sum() > 0: print(\"Rows removed:\", df.price.isnull().sum())\n",
        "  return df\n",
        "\n",
        "\n",
        "def clean_dict_gen(universe_dict):\n",
        "  \"\"\"Returns a dictionary of cleaned dataframes\"\"\"\n",
        "  cleaned_dict = {}\n",
        "  print(\"Included Instrument:\")\n",
        "  for df in universe_dict:\n",
        "    print(df)\n",
        "    cleaned_dict[df] = clean_data(universe_dict[df])\n",
        "    \n",
        "  return cleaned_dict\n",
        "\n",
        "\n",
        "universe_dict = clean_dict_gen(price_rename(universe_dict))"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Included Instrument:\n",
            "lme\n",
            "shfe\n",
            "com s\n",
            "com p\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79uLHimKtawo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = universe_dict[\"lme\"]  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EX6bQXD-gkTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_spawn(df):\n",
        "  \"\"\"Spawsn features for each instrument\n",
        "  Returns df with the following columns\n",
        "  Price\n",
        "  Log Returns\n",
        "  EWMA 1 day\n",
        "  EWMA 1 week\n",
        "  EWMA 1 month\n",
        "  EWMA 1 quarter\n",
        "  EWMA 6 months\n",
        "  EWMA 1 year\n",
        "  Rolling vol 1 week\n",
        "  Rolling vol 1 month\n",
        "  Rolling vol 1 quarter\n",
        "  \"\"\"\n",
        "  df[\"lg_return\"] = np.log(df.price) - np.log(df.price.shift(1))\n",
        "  #df[\"deciles_lg_return\"] = pd.qcut(df.lg_return, 10, labels=False)\n",
        "  df.lg_return.fillna(0, inplace=True)\n",
        "  \n",
        "  hlf_dict = {\"week\":5, \"month\":22, \"quarter\":66, \"half_year\":130, \"year\":261}\n",
        "\n",
        "  for half_life in hlf_dict:\n",
        "    df[\"ema_\" + half_life] = df.price.ewm(span=hlf_dict[half_life]).mean()\n",
        "    \n",
        "  for i, half_life in enumerate(hlf_dict):\n",
        "    if i < 3:\n",
        "      df[\"roll_vol_\" + half_life] = df.price.rolling(window=hlf_dict[half_life]).std(ddof=0)\n",
        "  \n",
        "  df.dropna(inplace=True)\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PZ00oJij6uK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = feature_spawn(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki2dJCGNkOVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_view(df):\n",
        "  \"\"\"Visualises the features for an instrument\"\"\"\n",
        "  fig, axarr = plt.subplots(len(df.columns), 1, figsize=(10, 4 * len(df.columns)))\n",
        "\n",
        "  for ax, df_name in zip(axarr.flatten(), df.columns):\n",
        "      ax.set_title(df_name)\n",
        "      ax.plot(df.index, df[df_name])\n",
        "      ax.grid()\n",
        "      ax.legend()\n",
        "      \n",
        "  plt.show()\n",
        "# feature_view(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkbQMnrNsrkd",
        "colab_type": "text"
      },
      "source": [
        "## PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZinko9QvVAb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1f01b8d8-df9e-43ee-e105-80486c06d8be"
      },
      "source": [
        "def dimenionality_selector(df):\n",
        "  \"\"\"Returns the number of dimensions that reaches the \n",
        "  threshold level of desired variance\"\"\"\n",
        "  for n_dim in range(1, 11):\n",
        "    pca = PCA(n_components=n_dim)\n",
        "    pca.fit(df)\n",
        "    if sum(pca.explained_variance_ratio_) > 0.99: \n",
        "      print(\"Number of dimensions:\", n_dim)\n",
        "      return n_dim\n",
        "  print(\"No level of dimensionality reaches threshold variance level\")\n",
        "  return None\n",
        "\n",
        "    \n",
        "n_dim = dimenionality_selector(df)"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of dimensions: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcIj5gTTsvZb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "03e36b2c-92fa-4624-cabb-585702918d84"
      },
      "source": [
        "# Creating PCA object\n",
        "pca = PCA(n_components=n_dim)\n",
        "# Fitting and transforming PCA data\n",
        "pca.fit(df)\n",
        "pca_reduced = pca.transform(df) \n",
        "\n",
        "print(\"Explained Variance:\", pca.explained_variance_ratio_, \n",
        "     \"\\nExplained Variance Sum:\", sum(pca.explained_variance_ratio_))\n",
        "\n",
        "# df_pca = pd.DataFrame(pca_reduced, index=df.index) \n",
        "# df_inverse = pd.DataFrame(pca.inverse_transform(pca_reduced), index=df.index, columns=df.columns)"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Explained Variance: [0.93443161 0.05385666 0.00543059] \n",
            "Explained Variance Sum: 0.9937188687776095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpLFV2GXwU_f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "1526e5de-1d40-4776-c5f5-bab8c15add59"
      },
      "source": [
        "for df_name in universe_dict:\n",
        "  universe_dict[df_name] = feature_spawn(universe_dict[df_name])\n",
        "  print(universe_dict[df_name].iloc[0:3])"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             price  lg_return  ...  roll_vol_month  roll_vol_quarter\n",
            "date                           ...                                  \n",
            "2007-06-07  7506.0   0.000800  ...      293.775879        652.807421\n",
            "2007-06-08  7220.0  -0.038848  ...      265.816407        632.438628\n",
            "2007-06-11  7445.5   0.030755  ...      233.317850        606.059879\n",
            "\n",
            "[3 rows x 10 columns]\n",
            "              price  lg_return  ...  roll_vol_month  roll_vol_quarter\n",
            "date                            ...                                  \n",
            "2007-06-27  60450.0  -0.029824  ...     1276.421344       3891.090495\n",
            "2007-06-28  61610.0   0.019008  ...     1329.865152       3873.242760\n",
            "2007-06-29  63150.0   0.024689  ...     1330.412615       3840.450525\n",
            "\n",
            "[3 rows x 10 columns]\n",
            "             price  lg_return  ...  roll_vol_month  roll_vol_quarter\n",
            "date                           ...                                  \n",
            "1996-10-10  0.9320   0.017316  ...        0.018157          0.022176\n",
            "1996-10-11  0.9315  -0.000537  ...        0.018738          0.022298\n",
            "1996-10-14  0.9150  -0.017872  ...        0.017333          0.021997\n",
            "\n",
            "[3 rows x 10 columns]\n",
            "              price  lg_return  ...  roll_vol_month  roll_vol_quarter\n",
            "date                            ...                                  \n",
            "2007-05-29  29145.0  -0.011191  ...     1148.710815       2380.608200\n",
            "2007-05-30  28191.0  -0.033281  ...     1275.231536       2485.335653\n",
            "2007-05-31  27500.0  -0.024817  ...     1429.808116       2604.997731\n",
            "\n",
            "[3 rows x 10 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smydNIiBzrV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}