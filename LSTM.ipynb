{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "67j8odKJJQL_"
   },
   "source": [
    "## Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qd88JeQfrEzc",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from deeplearning import *\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from preprocessing import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from utils import *\n",
    "import warnings\n",
    "\n",
    "# plt.style.use('dark_background')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insuring that training is done on GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available!\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
    "    print(\"Cuda installed! Running on GPU!\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"No GPU available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Data/\"\n",
    "universe_dict = universe_select(path, \"Cu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4k8FIHASpHfv"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ki2dJCGNkOVE",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Included Instrument:\n",
      "cu_shfe\n",
      "cu_lme\n",
      "cu_comex_p\n",
      "cu_comex_s\n",
      "peso\n",
      "sol\n",
      "bdi\n",
      "ted\n",
      "vix\n",
      "skew\n",
      "gsci\n"
     ]
    }
   ],
   "source": [
    "# Renaming the columns to price\n",
    "universe_dict = price_rename(universe_dict)\n",
    "# Cleaning the dataset of any erroneous datapoints\n",
    "universe_dict = clean_dict_gen(universe_dict)\n",
    "# Making sure that all the points in the window have consistent lenght\n",
    "universe_dict = truncate_window_length(universe_dict)\n",
    "df_full = generate_dataset(universe_dict, lg_returns_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target column represents the log returns at one forecast length out in the future for the instrument of interest (aluminium or copper prices on the London Metals Exchange). \n",
    "\n",
    "To normalise the independent variables, the 1 day log returns between closing prices have been used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualise the plots\n",
    "# visualise_universe(universe_dict)\n",
    "df = df_full[[\"target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cu_shfe</th>\n",
       "      <th>cu_lme</th>\n",
       "      <th>cu_comex_p</th>\n",
       "      <th>cu_comex_s</th>\n",
       "      <th>peso</th>\n",
       "      <th>sol</th>\n",
       "      <th>bdi</th>\n",
       "      <th>ted</th>\n",
       "      <th>vix</th>\n",
       "      <th>skew</th>\n",
       "      <th>gsci</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-09-13</th>\n",
       "      <td>0.001583</td>\n",
       "      <td>-0.013602</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.055554</td>\n",
       "      <td>-0.000558</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.029244</td>\n",
       "      <td>-0.004276</td>\n",
       "      <td>-0.064091</td>\n",
       "      <td>-0.048458</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>-0.001404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-09-14</th>\n",
       "      <td>0.025695</td>\n",
       "      <td>-0.006098</td>\n",
       "      <td>-0.003100</td>\n",
       "      <td>-0.104881</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>-0.001692</td>\n",
       "      <td>0.018715</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.032559</td>\n",
       "      <td>-0.008086</td>\n",
       "      <td>-0.010694</td>\n",
       "      <td>0.021675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-09-15</th>\n",
       "      <td>-0.027710</td>\n",
       "      <td>-0.021468</td>\n",
       "      <td>-0.019557</td>\n",
       "      <td>0.041104</td>\n",
       "      <td>-0.001172</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.012050</td>\n",
       "      <td>0.002636</td>\n",
       "      <td>0.018019</td>\n",
       "      <td>0.124060</td>\n",
       "      <td>-0.004952</td>\n",
       "      <td>0.043012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-09-18</th>\n",
       "      <td>0.006177</td>\n",
       "      <td>0.024153</td>\n",
       "      <td>0.030146</td>\n",
       "      <td>0.032495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000924</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>-0.060186</td>\n",
       "      <td>0.007824</td>\n",
       "      <td>0.013450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-09-19</th>\n",
       "      <td>0.023214</td>\n",
       "      <td>0.007613</td>\n",
       "      <td>-0.012512</td>\n",
       "      <td>0.138083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.000935</td>\n",
       "      <td>-0.000202</td>\n",
       "      <td>0.016835</td>\n",
       "      <td>-0.018385</td>\n",
       "      <td>-0.019642</td>\n",
       "      <td>0.025225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cu_shfe    cu_lme  cu_comex_p  cu_comex_s      peso       sol  \\\n",
       "date                                                                         \n",
       "2006-09-13  0.001583 -0.013602    0.000590    0.055554 -0.000558  0.000307   \n",
       "2006-09-14  0.025695 -0.006098   -0.003100   -0.104881  0.000707 -0.001692   \n",
       "2006-09-15 -0.027710 -0.021468   -0.019557    0.041104 -0.001172  0.000154   \n",
       "2006-09-18  0.006177  0.024153    0.030146    0.032495  0.000000 -0.000924   \n",
       "2006-09-19  0.023214  0.007613   -0.012512    0.138083  0.000000  0.000000   \n",
       "\n",
       "                 bdi       ted       vix      skew      gsci    target  \n",
       "date                                                                    \n",
       "2006-09-13  0.029244 -0.004276 -0.064091 -0.048458  0.002624 -0.001404  \n",
       "2006-09-14  0.018715  0.005088  0.032559 -0.008086 -0.010694  0.021675  \n",
       "2006-09-15  0.012050  0.002636  0.018019  0.124060 -0.004952  0.043012  \n",
       "2006-09-18  0.004920  0.002023  0.001699 -0.060186  0.007824  0.013450  \n",
       "2006-09-19 -0.000935 -0.000202  0.016835 -0.018385 -0.019642  0.025225  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.head(5)\n",
    "# df_full.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise data\n",
    "\n",
    "Split into validation data and test data\n",
    "\n",
    "Use validation to tune hyperparameters\n",
    "\n",
    "Perform predictions on the test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataset for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df_full.loc[:, df_full.columns != 'target']\n",
    "df_y = df_full.loc[:, df_full.columns == 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLearning():\n",
    "    \"\"\"Class to perform training and validation for a given model\"\"\"\n",
    "    def __init__(self, df_X, df_y,\n",
    "                 #model, \n",
    "                 #optimiser, \n",
    "                 loss_function=nn.CrossEntropyLoss(),\n",
    "                 device=\"cpu\", seed=42):\n",
    "        \n",
    "        self.df_X = df_X\n",
    "        self.df_y = df_y\n",
    "   \n",
    "        #self.model = model\n",
    "        #self.optimiser = optimiser\n",
    "        self.loss_function = loss_function\n",
    "        self.device = device\n",
    "        self.seed = seed\n",
    "        \n",
    "        assert (type(self.df_X) == pd.DataFrame)\n",
    "        assert (type(self.df_y) == pd.DataFrame)\n",
    "        assert (len(self.df_X.index) == len(self.df_y.index))\n",
    "        assert (len(self.df_X.index) > 0)\n",
    "        \n",
    "        self.X_train = None\n",
    "        self.X_val = None\n",
    "        self.X_test = None\n",
    "        \n",
    "        self.y_train = None\n",
    "        self.y_val = None\n",
    "        self.y_test = None\n",
    "        \n",
    "        \n",
    "    def train_val_test(self):\n",
    "        \"\"\"Splits the dataframes in to a training, validation\n",
    "        and test set and creates torch tensors from the underlying\n",
    "        numpy arrays\"\"\"\n",
    "        # Splitting the sets into train, test and validation\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.df_X, self.df_y, test_size=0.2, shuffle=False)\n",
    "        \n",
    "        self.X_train, self.X_val, self.y_train, self.y_val = train_test_split(self.X_train, self.y_train, test_size=0.25, shuffle=False)\n",
    "\n",
    "        print(\"Train Length: \\t\\t%i\\nValidation Length: \\t%i\\nTest Length:\\t\\t%i\" % (len(X_train), len(X_val), len(X_test)))\n",
    "        \n",
    "        # Tensor of training data\n",
    "        self.X_train = torch.from_numpy(self.X_train.values).float()\n",
    "        self.y_train = torch.from_numpy(self.y_train.values).float()\n",
    "\n",
    "        # Tensor of training labels\n",
    "        self.X_val = torch.from_numpy(self.X_val.values).float()\n",
    "        self.y_val = torch.from_numpy(self.y_val.values).float()\n",
    "\n",
    "        #  Tensor of test data\n",
    "        self.X_test = torch.from_numpy(self.X_test.values).float()\n",
    "        self.y_test = torch.from_numpy(self.y_test.values).float()\n",
    "\n",
    "        # Size Check\n",
    "        print(\"\\nX Train Shape:\\t\\t\", self.X_train.size())\n",
    "        print(\"X Val Shape:\\t\\t\", self.X_val.size())\n",
    "        print(\"X Test Shape:\\t\\t\", self.X_test.size())\n",
    "\n",
    "        print(\"\\ny Train Shape:\\t\\t\", self.y_train.size())\n",
    "        print(\"y Val Shape:\\t\\t\", self.y_val.size())\n",
    "        print(\"y Test Shape:\\t\\t\", self.y_test.size())\n",
    "        \n",
    "    def normalise(self):\n",
    "        \"\"\"Normalizes the data using MaxMinScaler, which\n",
    "            was chosen because it preserves the original \n",
    "            scale and doesn't reduce effect of outliers\"\"\"\n",
    "        scaler = MinMaxScaler()\n",
    "        \n",
    "        # Normalize the validation and test set by the same\n",
    "        # scale as the training data. Needed for training to\n",
    "        # be correctly scaled\n",
    "        \n",
    "        self.X_train = scaler.fit_transform(self.X_train)\n",
    "        self.X_val = scaler.transform(self.X_val)\n",
    "        self.X_test = scaler.transform(self.X_test)\n",
    "        \n",
    "        \"\"\"TODO implement output scaling for MTL because \n",
    "        otherwise the scale of the different outputs will\n",
    "        lead to dominance of some tasks\"\"\"\n",
    "        \n",
    "    def train(self):\n",
    "        return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Length: \t\t1999\n",
      "Validation Length: \t667\n",
      "Test Length:\t\t667\n",
      "\n",
      "X Train Shape:\t\t torch.Size([1999, 11])\n",
      "X Val Shape:\t\t torch.Size([667, 11])\n",
      "X Test Shape:\t\t torch.Size([667, 11])\n",
      "\n",
      "y Train Shape:\t\t torch.Size([1999, 1])\n",
      "y Val Shape:\t\t torch.Size([667, 1])\n",
      "y Test Shape:\t\t torch.Size([667, 1])\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "lr = 1e-2\n",
    "momentum = 0.5\n",
    "batch_size = 64\n",
    "test_batch_size = 1000\n",
    "n_epochs = 2\n",
    "weight_decay=0\n",
    "\n",
    "df_X = df_full.loc[:, df_full.columns != 'target']\n",
    "df_y = df_full.loc[:, df_full.columns == 'target']\n",
    "\n",
    "# optimiser = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "\"\"\"Do I need to declare a data explicitly in the dataset\"\"\"\n",
    "\n",
    "learning = DeepLearning(df_X, df_y)\n",
    "# Splitting the data into the train, validation and test sets\n",
    "learning.train_val_test()\n",
    "# Scaling the data by the training dataset\n",
    "learning.normalise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMnet(nn.Module):\n",
    "    \"\"\"A Long Short Term Memory network\n",
    "    model\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LSTMnet, self, input_dim, hidden_dim, num_layers, dropout=0).__init__()\n",
    "        \n",
    "        # Input dimensions\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        # Hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # Number of hidden layers\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Dropout rate\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # The output dimensions\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # batch_first=True causes input/output tensors to be of shape\n",
    "        # (batch_dim, seq_dim, feature_dim)\n",
    "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers,\n",
    "                            dropout=self.dropout, batch_first=True)\n",
    "\n",
    "        # Output layer\n",
    "        self.fc = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "        \n",
    "        \n",
    "    def forward(self, x)\n",
    "    \n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "    \n",
    "        def init_hidden(self):\n",
    "        # This is what we'll initialise our hidden state as\n",
    "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
    "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.DataFrame(data={\"A\": [1, 2, 5, 10, 15], \"B\": [0.1, 0.2, 0.3, 0.6, 0.9]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_full[[\"target\"]]\n",
    "# Taking t-1 to be the value for t\n",
    "df[\"persistance\"] = df.shift(1)\n",
    "df.dropna(inplace=True)\n",
    "# Calculating metrics for these columns\n",
    "MSE, MAE, MDE = evaluate(df, \"target\", \"persistance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              target  persistance\n",
      "date                             \n",
      "2006-09-14  0.021675    -0.001404\n",
      "2006-09-15  0.043012     0.021675\n",
      "2006-09-18  0.013450     0.043012\n",
      "2006-09-19  0.025225     0.013450\n",
      "2006-09-20  0.024843     0.025225\n",
      "              target  persistance\n",
      "date                             \n",
      "2019-06-24 -0.000589     0.004104\n",
      "2019-06-25 -0.026401    -0.000589\n",
      "2019-06-26 -0.010480    -0.026401\n",
      "2019-06-27 -0.011358    -0.010480\n",
      "2019-06-28 -0.015457    -0.011358\n"
     ]
    }
   ],
   "source": [
    "print(df[:5])\n",
    "print(df[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MDE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>persistance</th>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.017105</td>\n",
       "      <td>0.465585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  MSE       MAE       MDE\n",
       "Name                                     \n",
       "persistance  0.000582  0.017105  0.465585"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Placing in results dataframe\n",
    "results = pd.DataFrame(columns={\"MSE\", \"MAE\", \"MDE\"})\n",
    "results.index.name = 'Name'\n",
    "results.head()\n",
    "results.loc[\"persistance\"] = [MSE, MAE, MDE] \n",
    "results.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Chai_Base.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
